{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import XML package\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# create the XML Element Tree object\n",
    "tree = ET.parse('supporting-files/exampleresearcharticle.xml')\n",
    "type(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the element that I want\n",
    "root = tree.getroot()\n",
    "type(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nChildren of root\")\n",
    "\n",
    "# print out each direct child element's tag in the root object\n",
    "for child in root:\n",
    "    # .tag attribute being used here\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use XPATH to find specific elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the first element matching the xpath request\n",
    "title = root.find('./fm/bibl/title')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# placeholder for text\n",
    "title_text = \"\"\n",
    "\n",
    "# loops through title element\n",
    "for p in title:\n",
    "    # in-place appends placeholder for text\n",
    "    title_text += p.text\n",
    "title_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out the Author's email address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# element.findall() method finds all matching subelements by tag name or path\n",
    "# loops and prints for each item found\n",
    "for a in root.findall('./fm/bibl/aug/au'):\n",
    "    email = a.find('email').text\n",
    "    if email is not None:\n",
    "        print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Focus in on more specific data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article_file = \"supporting-files/exampleResearchArticle.xml\"\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def get_authors(root):\n",
    "    authors = []\n",
    "    for author in root.findall('./fm/bibl/aug/au'):\n",
    "        data = {\n",
    "                \"fnm\": None,\n",
    "                \"snm\": None,\n",
    "                \"email\": None,\n",
    "                \"insr\": []\n",
    "        }\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        data['fnm'] = author.find('fnm').text\n",
    "        data['snm'] = author.find('snm').text\n",
    "        data['email'] = author.find('email').text\n",
    "        insr = author.findall('./insr')\n",
    "        for i in insr:\n",
    "            data['insr'].append(i.attrib['iid'])\n",
    "\n",
    "        authors.append(data)\n",
    "\n",
    "    return authors\n",
    "root = get_root(article_file)\n",
    "data = get_authors(root)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use parsing to count number of tags in an XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# REQS:\n",
    "    # make dict\n",
    "# EX:\n",
    "    # REQS:\n",
    "        # make dict\n",
    "    # RULES:\n",
    "        # node must be uniquely identified\n",
    "        # node must be added to a dict and not repeated\n",
    "        # use xml package to make root\n",
    "    # COMP:\n",
    "        # iterate over each line\n",
    "            # if does not contain '/'\n",
    "                # add to dict\n",
    "                    # if exists already, add and increment value by 1\n",
    "                    # else, just add\n",
    "    # DECOMP:\n",
    "        # Iterate over each line, add node name to dict with value 1\n",
    "            # if item is not in dict already, add and make value 1\n",
    "            # if in dict already, increment that key's value by 1\n",
    "    \n",
    "def count_tags(filename):\n",
    "    # create XML tree objet\n",
    "    tree = ET.parse(filename)\n",
    "    \n",
    "    # create root object to parse the XML tree\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # holds all tags (keys) and counts for each instance of key (value)\n",
    "    tags_dict = {}\n",
    "    \n",
    "    # fills in dict with tags and counts\n",
    "    for element in tree.iter():\n",
    "        if element.tag in tags_dict:\n",
    "            tags_dict[element.tag] += 1\n",
    "        else:\n",
    "            tags_dict[element.tag] = 1\n",
    "            \n",
    "    return tags_dict\n",
    "\n",
    "file = 'sample-data/example.osm'\n",
    "count_tags(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use ITERATIVE parsing to count number of tags in an XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# REQS:\n",
    "    # make dict\n",
    "# EX:\n",
    "    # REQS:\n",
    "        # make dict\n",
    "    # RULES:\n",
    "        # node must be uniquely identified\n",
    "        # node must be added to a dict and not repeated\n",
    "        # use xml package to make root\n",
    "    # COMP:\n",
    "        # iterate over each line\n",
    "            # if does not contain '/'\n",
    "                # add to dict\n",
    "                    # if exists already, add and increment value by 1\n",
    "                    # else, just add\n",
    "    # DECOMP:\n",
    "        # Iterate over each line, add node name to dict with value 1\n",
    "            # if item is not in dict already, add and make value 1\n",
    "            # if in dict already, increment that key's value by 1\n",
    "    \n",
    "def count_tags(filename):\n",
    "    # holds all tags (keys) and counts for each instance of key (value)\n",
    "    tags_dict = {}\n",
    "    \n",
    "    # fills in dict with tags and counts\n",
    "    # note, here every time a start event is found\n",
    "    # the event and the element that it found\n",
    "    for event, element in ET.iterparse(filename, events=('start',)):\n",
    "        if element.tag in tags_dict:\n",
    "            tags_dict[element.tag] += 1\n",
    "            # just to show that .iterparse() returns the element\n",
    "            print(element)\n",
    "        else:\n",
    "            tags_dict[element.tag] = 1\n",
    "            # just to show that .iterparse() returns the event\n",
    "            print(event)\n",
    "            \n",
    "    return tags_dict\n",
    "\n",
    "file = 'sample-data/example.osm'\n",
    "count_tags(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing an XML file in its entirety with the ElementTree module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the ElementTree XML API\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# path to the XML file\n",
    "OSM_PATH = \"sample_data/example5.osm\"\n",
    "\n",
    "# create the ElementTree object\n",
    "tree_obj = ET.parse(OSM_PATH)\n",
    "tree_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ElementTree object itself is not iterable. Its root element (parent to all other elements and of type Element), however, is a reference to the tree and is iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return the root element of the tree\n",
    "root = tree_obj.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate over the children and children's children\n",
    "for child in root:\n",
    "    if child.tag == \"node\":\n",
    "        for child2 in child:\n",
    "            print(child2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging purposes, dump() returns a complete representation of ALL elements of an Element object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing an XML file incrementally with the ElementTree module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "OSM_PATH = \"sample_data/example5.osm\"\n",
    "\n",
    "# create the IterParseIterator object\n",
    "iter_obj = ET.iterparse(OSM_PATH, events=('start','end'))\n",
    "iter_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IterParseIterator object is directly iterable, returning (event, elem) tuple pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event, root = next(iter_obj)\n",
    "print(event)\n",
    "print(root)\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remainder of the object (all elements and sub-elements) can be iterated over in a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for event, elem in iter_obj:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear() removes all the insides of any given element - so here clearing the root removes everything inside of it including its children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The problem with memory and incremental parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental parsing of very large XML files is problematic because it can create a very large tree that can gobble up loads of computer memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from sys import getsizeof\n",
    "\n",
    "OSM_PATH = \"sample_data/example5.osm\"\n",
    "\n",
    "# create the IterParseIterator object\n",
    "iterobj = ET.iterparse(OSM_PATH, events=('start','end'))\n",
    "iterobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out the reference to the root element\n",
    "event, root = next(iterobj)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid making a very large tree when parsing a very large XML file, the clear() method from ElementTree can clear each element being built with each iteration of the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate over all remaining, clearing any elements with certain tags\n",
    "for event, elem in iterobj:\n",
    "    if (elem.tag == \"bounds\") or (elem.tag == \"node\") or (elem.tag == \"way\") or (elem.tag == \"relation\"):\n",
    "        elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the root reference was returned first. Then references to all the other elements were returned in the for loop, but when dumping the root those empty tags (the elements that were cleared but their tags left as artifacts) are still there. This demonstrates the fact that each unpacked element is a REFERENCE to the tree!\n",
    "\n",
    "Still, clearing elements like this is only slightly less problematic because we're now left with the parent element and a bunch of child elements with their internals cleared out.\n",
    "\n",
    "To fix this, we can clear everything within the root element with each iteration of the for loop. This clears out the sub-element that has just been added to the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "OSM_PATH = \"sample_data/example5.osm\"\n",
    "\n",
    "# create the IterParseIterator object\n",
    "iterobj = ET.iterparse(OSM_PATH, events=('start','end'))\n",
    "iterobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event, root = next(iterobj)\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without clearing anything, dumping the root shows that, if iterated over, the tree is fully populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearing the root with each iteration of the below for loop will remove each element just as it's added to the tree. So the tree never has an opportunity to be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for event, elem in iterobj:\n",
    "    print(\"Element was added to the tree\")\n",
    "    print(\"Element was: \", elem)\n",
    "    root.clear()\n",
    "    print(\"\\nAll elements cleared via clear()\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that dumping the root after the iteration process leaves us with an empty root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more memory being gummed up!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_tags': [], 'node': {'version': '7', 'lon': -87.6866303, 'timestamp': '2012-03-28T18:31:23Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261114295, 'lat': 41.9730791, 'changeset': 11129782}}\n",
      "{'node_tags': [], 'node': {'version': '6', 'lon': -87.6878512, 'timestamp': '2011-06-15T17:04:54Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261114296, 'lat': 41.9730416, 'changeset': 8448766}}\n",
      "{'node_tags': [], 'node': {'version': '5', 'lon': -87.6939548, 'timestamp': '2011-06-29T14:14:14Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261114299, 'lat': 41.9729565, 'changeset': 8581395}}\n",
      "{'node_tags': [], 'node': {'version': '5', 'lon': -87.6976025, 'timestamp': '2011-06-29T14:14:14Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261146436, 'lat': 41.970738, 'changeset': 8581395}}\n",
      "{'node_tags': [], 'node': {'version': '7', 'lon': -87.6988576, 'timestamp': '2011-06-29T14:14:15Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261147304, 'lat': 41.9740068, 'changeset': 8581395}}\n",
      "{'node_tags': [], 'node': {'version': '5', 'lon': -87.6938669, 'timestamp': '2011-06-29T14:14:14Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261224274, 'lat': 41.9707656, 'changeset': 8581395}}\n",
      "{'node_tags': [], 'node': {'version': '47', 'lon': -87.6890403, 'timestamp': '2011-06-15T16:55:37Z', 'uid': 451048, 'user': 'bbmiller', 'id': 293816175, 'lat': 41.9730154, 'changeset': 8448766}}\n",
      "{'node_tags': [], 'node': {'version': '37', 'lon': -87.6891198, 'timestamp': '2013-03-13T07:46:29Z', 'uid': 567034, 'user': 'Umbugbene', 'id': 305896090, 'lat': 41.9749225, 'changeset': 15348240}}\n",
      "{'node_tags': [], 'node': {'version': '12', 'lon': -87.701243, 'timestamp': '2013-03-13T08:02:56Z', 'uid': 567034, 'user': 'Umbugbene', 'id': 317636974, 'lat': 41.9740292, 'changeset': 15348240}}\n",
      "{'node_tags': [], 'node': {'version': '13', 'lon': -87.6979712, 'timestamp': '2013-03-13T08:08:01Z', 'uid': 567034, 'user': 'Umbugbene', 'id': 317636971, 'lat': 41.9740556, 'changeset': 15348240}}\n",
      "{'node_tags': [], 'node': {'version': '2', 'lon': -87.7012048, 'timestamp': '2013-02-05T22:43:49Z', 'uid': 567034, 'user': 'Umbugbene', 'id': 317637399, 'lat': 41.9705609, 'changeset': 14927972}}\n",
      "{'node_tags': [], 'node': {'version': '2', 'lon': -87.7012109, 'timestamp': '2013-02-05T22:43:49Z', 'uid': 567034, 'user': 'Umbugbene', 'id': 317637398, 'lat': 41.9706972, 'changeset': 14927972}}\n",
      "{'node_tags': [], 'node': {'version': '3', 'lon': -87.6847998, 'timestamp': '2011-06-15T17:04:54Z', 'uid': 451048, 'user': 'bbmiller', 'id': 365214872, 'lat': 41.973113, 'changeset': 8448766}}\n",
      "{'node_tags': [], 'node': {'version': '6', 'lon': -87.6988886, 'timestamp': '2011-06-29T14:14:15Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261299091, 'lat': 41.9747482, 'changeset': 8581395}}\n",
      "{'node_tags': [], 'node': {'version': '6', 'lon': -87.6841979, 'timestamp': '2011-06-15T17:04:54Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261114294, 'lat': 41.9731219, 'changeset': 8448766}}\n",
      "{'node_tags': [], 'node': {'version': '4', 'lon': -87.7000019, 'timestamp': '2009-12-13T00:36:09Z', 'uid': 147510, 'user': 'woodpeck_fixbot', 'id': 261210804, 'lat': 41.9707217, 'changeset': 3359748}}\n",
      "{'node_tags': [], 'node': {'version': '7', 'lon': -87.6922652, 'timestamp': '2011-06-29T14:14:15Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261221422, 'lat': 41.9748542, 'changeset': 8581395}}\n",
      "{'node_tags': [{'value': 'traffic_signals', 'type': 'regular', 'id': '261221424', 'key': 'highway'}], 'node': {'version': '7', 'lon': -87.6923639, 'timestamp': '2011-06-29T14:14:15Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261221424, 'lat': 41.9758794, 'changeset': 8581395}}\n",
      "{'node_tags': [{'value': 'Chicago', 'type': 'regular', 'id': '2406124091', 'key': 'addr:city'}, {'value': '5157', 'type': 'regular', 'id': '2406124091', 'key': 'addr:housenumber'}, {'value': '60625', 'type': 'regular', 'id': '2406124091', 'key': 'addr:postcode'}, {'value': 'North Lincoln Ave', 'type': 'regular', 'id': '2406124091', 'key': 'addr:street'}, {'value': 'restaurant', 'type': 'regular', 'id': '2406124091', 'key': 'amenity'}, {'value': 'mexican', 'type': 'regular', 'id': '2406124091', 'key': 'cuisine'}, {'value': 'La Cabana De Don Luis', 'type': 'regular', 'id': '2406124091', 'key': 'name'}, {'value': 'no', 'type': 'regular', 'id': '2406124091', 'key': 'outdoor_seating'}, {'value': '1 (773)-271-5176', 'type': 'regular', 'id': '2406124091', 'key': 'phone'}, {'value': 'no', 'type': 'regular', 'id': '2406124091', 'key': 'smoking'}, {'value': 'yes', 'type': 'regular', 'id': '2406124091', 'key': 'takeaway'}], 'node': {'version': '2', 'lon': -87.6921867, 'timestamp': '2013-08-03T16:43:42Z', 'uid': 1219059, 'user': 'linuxUser16', 'id': 2406124091, 'lat': 41.975703, 'changeset': 17206049}}\n",
      "{'node_tags': [{'value': 'Chicago', 'type': 'regular', 'id': '2636084635', 'key': 'addr:city'}, {'value': 'US', 'type': 'regular', 'id': '2636084635', 'key': 'addr:country'}, {'value': '4874', 'type': 'regular', 'id': '2636084635', 'key': 'addr:housenumber'}, {'value': '60625', 'type': 'regular', 'id': '2636084635', 'key': 'addr:postcode'}, {'value': 'Illinois', 'type': 'regular', 'id': '2636084635', 'key': 'addr:state'}, {'value': 'N. Lincoln Ave', 'type': 'regular', 'id': '2636084635', 'key': 'addr:street'}, {'value': 'Matty Ks', 'type': 'regular', 'id': '2636084635', 'key': 'name'}, {'value': '(773)-654-1347', 'type': 'regular', 'id': '2636084635', 'key': 'phone'}, {'value': 'doityourself', 'type': 'regular', 'id': '2636084635', 'key': 'shop'}, {'value': 'GPS', 'type': 'regular', 'id': '2636084635', 'key': 'source'}], 'node': {'version': '1', 'lon': -87.6900344, 'timestamp': '2014-01-25T01:56:10Z', 'uid': 1219059, 'user': 'linuxUser16', 'id': 2636084635, 'lat': 41.9705219, 'changeset': 20187349}}\n",
      "{'node_tags': [], 'node': {'version': '6', 'lon': -87.6963097, 'timestamp': '2011-06-29T14:14:13Z', 'uid': 451048, 'user': 'bbmiller', 'id': 261198953, 'lat': 41.9707413, 'changeset': 8581395}}\n",
      "{'node_tags': [{'value': 'fast_food', 'type': 'regular', 'id': '757860928', 'key': 'amenity'}, {'value': 'sausage', 'type': 'regular', 'id': '757860928', 'key': 'cuisine'}, {'value': \"Shelly's Tasty Freeze\", 'type': 'regular', 'id': '757860928', 'key': 'name'}], 'node': {'version': '2', 'lon': -87.6920102, 'timestamp': '2010-07-22T16:16:51Z', 'uid': 26299, 'user': 'uboot', 'id': 757860928, 'lat': 41.9747374, 'changeset': 5288876}}\n",
      "{'way_tags': [{'value': 'service', 'type': 'regular', 'id': '258219703', 'key': 'highway'}], 'way': {'version': '1', 'timestamp': '2014-01-25T02:01:54Z', 'uid': 1219059, 'id': 258219703, 'user': 'linuxUser16', 'changeset': 20187382}, 'way_nodes': [{'id': '258219703', 'node_id': 2636086179, 'position': 1}, {'id': '258219703', 'node_id': 2636086178, 'position': 1}, {'id': '258219703', 'node_id': 2636086177, 'position': 1}, {'id': '258219703', 'node_id': 2636086176, 'position': 1}]}\n",
      "{'node_tags': [{'value': 'Village Hall', 'type': 'regular', 'id': '1683602133', 'key': 'addr:housename'}, {'value': '1400', 'type': 'regular', 'id': '1683602133', 'key': 'addr:housenumber'}, {'value': '60067', 'type': 'regular', 'id': '1683602133', 'key': 'addr:postcode'}, {'value': 'Baldwin Rd.', 'type': 'regular', 'id': '1683602133', 'key': 'addr:street'}, {'value': 'townhall', 'type': 'regular', 'id': '1683602133', 'key': 'amenity'}, {'value': 'Village Hall', 'type': 'regular', 'id': '1683602133', 'key': 'name'}], 'node': {'version': '2', 'lon': -88.0780576, 'timestamp': '2012-03-20T18:56:44Z', 'uid': 634589, 'user': 'Jacobs Studios', 'id': 1683602133, 'lat': 42.1251718, 'changeset': 11043902}}\n",
      "{'way_tags': [{'value': '1412', 'type': 'regular', 'id': '209809850', 'key': 'addr:housenumber'}, {'value': 'West Lexington St.', 'type': 'regular', 'id': '209809850', 'key': 'addr:street'}, {'value': 'Lexington', 'type': 'regular', 'id': '209809850', 'key': 'addr:street:name'}, {'value': 'West', 'type': 'regular', 'id': '209809850', 'key': 'addr:street:prefix'}, {'value': 'Street', 'type': 'regular', 'id': '209809850', 'key': 'addr:street:type'}, {'value': 'yes', 'type': 'regular', 'id': '209809850', 'key': 'building'}, {'value': '1', 'type': 'regular', 'id': '209809850', 'key': 'building:levels'}, {'value': '366409', 'type': 'regular', 'id': '209809850', 'key': 'chicago:building_id'}], 'way': {'version': '1', 'timestamp': '2013-03-13T15:58:04Z', 'uid': 674454, 'id': 209809850, 'user': 'chicago-buildings', 'changeset': 15353317}, 'way_nodes': [{'id': '209809850', 'node_id': 2199822281, 'position': 1}, {'id': '209809850', 'node_id': 2199822390, 'position': 1}, {'id': '209809850', 'node_id': 2199822392, 'position': 1}, {'id': '209809850', 'node_id': 2199822369, 'position': 1}, {'id': '209809850', 'node_id': 2199822370, 'position': 1}, {'id': '209809850', 'node_id': 2199822284, 'position': 1}, {'id': '209809850', 'node_id': 2199822281, 'position': 1}]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": {\"id\":xxxx, \"user\":xxxx, ...}, \"node_tags\": []}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "# REQS\n",
    "    # investigate \n",
    "    # shape_element\n",
    "# EXEC\n",
    "    # investigate\n",
    "        # process_map called\n",
    "        # itatively process each XML element and write to the correct csv\n",
    "        # script-scope functions:\n",
    "            # get_element()\n",
    "            # UnicodeDictWriter()\n",
    "            # validate_element()\n",
    "    # shape_element\n",
    "        # *see above shape_element\n",
    "    \n",
    "    \n",
    "    \n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "from sample_data import schema\n",
    "\n",
    "OSM_PATH = \"sample_data/example5.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "# REQS\n",
    "    # input an iterparse Element object and return a dictionary\n",
    "# RULES\n",
    "    # correct element must be parsed and pieces mapped to dict as specified above\n",
    "    # conditional logic must be met\n",
    "# COMP\n",
    "    # break apart the element\n",
    "    # map (according to conditional logic) into a dict\n",
    "# DECOMP\n",
    "    # descipher whether or not element is a node or a way\n",
    "        # works, but also returns 'None'. Investigate if problematic\n",
    "    # print empty dicts (structure only)\n",
    "    # map items to dict\n",
    "        # map 'node' with node_attribs\n",
    "        # map 'node_tags' with tags\n",
    "            # create a dict\n",
    "                # initialize 'type' key field as \":\" temporarily\n",
    "            # append list with dict\n",
    "    # add conditional logic and ordering to mapping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    for child in element:\n",
    "        if child.tag == 'tag':\n",
    "            tag_dict = {'id':element.attrib['id'],\n",
    "                        'key':child.attrib['k'],\n",
    "                        'value':child.attrib['v'],\n",
    "                        'type':'regular' #setting as 'regular temporarily\n",
    "                       }\n",
    "            tags.append(tag_dict)\n",
    "            \n",
    "    if element.tag == 'node':\n",
    "        node_attribs = {'id':int(element.attrib['id']),\n",
    "                   'user':element.attrib['user'],\n",
    "                   'uid':int(element.attrib['uid']),\n",
    "                   'version':element.attrib['version'],\n",
    "                   'lat':float(element.attrib['lat']),\n",
    "                    'lon':float(element.attrib['lon']),\n",
    "                    'timestamp':element.attrib['timestamp'],\n",
    "                    'changeset':int(element.attrib['changeset'])\n",
    "                   }\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        way_attribs = {'id':int(element.attrib['id']),\n",
    "                      'user':element.attrib['user'],\n",
    "                      'uid':int(element.attrib['uid']),\n",
    "                      'version':element.attrib['version'],\n",
    "                      'timestamp':element.attrib['timestamp'],\n",
    "                      'changeset':int(element.attrib['changeset'])\n",
    "                      }\n",
    "        \n",
    "        \n",
    "        way_nodes = []\n",
    "        \n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                nd_dict = {'id':(element.attrib['id']),\n",
    "                          'node_id':int(child.attrib['ref']),\n",
    "                          'position':1} # placeholder as 1 temporarily\n",
    "                way_nodes.append(nd_dict)\n",
    "                \n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    \n",
    "    _, root = next(context)\n",
    "    \n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "        root.clear()\n",
    "\n",
    "        \n",
    "element_generator = get_element(OSM_PATH, tags=('node', 'way'))\n",
    "\n",
    "# test if key is there\n",
    "# for element in element_generator:\n",
    "#     for key,value in element.items():\n",
    "#         print(value)\n",
    "        \n",
    "for element in element_generator:\n",
    "    print(shape_element(element))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# def validate_element(element, validator, schema=SCHEMA):\n",
    "#     \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "#     if validator.validate(element, schema) is not True:\n",
    "#         field, errors = next(validator.errors.iteritems())\n",
    "#         message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "#         error_string = pprint.pformat(errors)\n",
    "        \n",
    "#         raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "# class UnicodeDictWriter(csv.DictWriter, object):\n",
    "#     \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "#     def writerow(self, row):\n",
    "#         super(UnicodeDictWriter, self).writerow({\n",
    "#             k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "#         })\n",
    "\n",
    "#     def writerows(self, rows):\n",
    "#         for row in rows:\n",
    "#             self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "\n",
    "# takes in osm file and validate as \"True\" or \"False\"\n",
    "# def process_map(file_in, validate):\n",
    "#     \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "#     # open files in write mode\n",
    "#     with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "#         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "#         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "#         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "#         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "#         # create writer objects\n",
    "#         nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "#         node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "#         ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "#         way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "#         way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "#         # write headers using field names specified in DictWriter constructor\n",
    "#         nodes_writer.writeheader()\n",
    "#         node_tags_writer.writeheader()\n",
    "#         ways_writer.writeheader()\n",
    "#         way_nodes_writer.writeheader()\n",
    "#         way_tags_writer.writeheader()\n",
    "\n",
    "#         # the Validator object instantiated here is callable to normalize \n",
    "#         # and/or validate any mapping against validation schema \n",
    "#         validator = cerberus.Validator()\n",
    "\n",
    "#         for element in get_element(file_in, tags=('node', 'way')):\n",
    "#             # Element object as as input to shape_element\n",
    "#                 # returns...\n",
    "#             el = shape_element(element)\n",
    "#             if el:\n",
    "#                 if validate is True:\n",
    "#                     validate_element(el, validator)\n",
    "#                 if element.tag == 'node':\n",
    "#                     nodes_writer.writerow(el['node'])\n",
    "#                     node_tags_writer.writerows(el['node_tags'])\n",
    "#                 elif element.tag == 'way':\n",
    "#                     ways_writer.writerow(el['way'])\n",
    "#                     way_nodes_writer.writerows(el['way_nodes'])\n",
    "#                     way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "#     # sample of the map when validating.\n",
    "#     process_map(OSM_PATH, validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "\n",
    "# REQS\n",
    "    # return a set of unique user IDs\n",
    "# EXEC\n",
    "    # get_user\n",
    "        # REQS: \n",
    "            # in: an element from XML\n",
    "            # out: a user id?\n",
    "        # RULES\n",
    "            # must pull value from 'uid' attribute\n",
    "        # COMP\n",
    "            # query the element for 'uid'\n",
    "        # DECOMP\n",
    "            # TRY: .attrib, print\n",
    "            # NEED: tell difference between elements with a uid, elements without\n",
    "    # process_map\n",
    "        # REQS: \n",
    "            # in: a filename/path\n",
    "            # out: a set of users\n",
    "        # RULES\n",
    "            # must call get_user()\n",
    "            # \n",
    "\n",
    "# returns a user id only if element contains one\n",
    "def get_user(element):\n",
    "    try:\n",
    "        return element.attrib['uid']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# creates and returns a set of unique user ids\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        users.add(get_user(element))\n",
    "\n",
    "    # removes 'None' from set\n",
    "    users.remove(None)\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map('sample-data/example3.osm')\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 6\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "'''\n",
    "NOTES:\n",
    "- Node: consists of a single point in space defined by its latitude, longitude and node id. It can have one or more tags.\n",
    "- Way: an ordered list of nodes which normally also has at least one tag or is included within a Relation. Can\n",
    "use nodes to make shapes and/or lines.\n",
    "- Relation: consists of one or more tags and also an ordered list of one or more nodes, ways and/or relations \n",
    "as members which is used to define logical or geographic relationships between other elements.\n",
    "'''\n",
    "\n",
    "# REQS\n",
    "    # populate mapping dict with all unexpected values mapped to what they should be\n",
    "    # complete update_name function to fix any incorrect values\n",
    "# EXEC\n",
    "    # mapping dict\n",
    "        # REQS\n",
    "            # manually fill all unexpected values found in OMS file into the mapping variable\n",
    "            # print out each last-line from address for each relevant element and inspect visually\n",
    "        # RULES\n",
    "            # unexpected value must be from OSM file, corrected value\n",
    "        # COMP\n",
    "            # EXPERIMENT: map out control flow to know where to print out\n",
    "        # DECOM\n",
    "            # done\n",
    "    # update_name to fix incorrect values\n",
    "        # REQS\n",
    "            # input: an incorrect street name and a mapping dict\n",
    "            # output: a corrected street name\n",
    "        # RULES\n",
    "            # the incorrect street name must match a key from the mapping dict\n",
    "        # COMP\n",
    "            # if incorrect street nmae is a key in mapping dict:\n",
    "                # set name variable to to the corresponding key's value\n",
    "        # DECOMP\n",
    "            # EXP: what is control flow leading my update_name?\n",
    "                # is called and supplied incorrect name and mapping\n",
    "            # TEST: print mapping dict\n",
    "            # EXP: can a string be aligned to a key in a dict?\n",
    "            # TEST: reassign name to output from regex query, then try is in mapping.\n",
    "            # TRY: Need to return the full street\n",
    "                # append corrected name from mapping to previous part of street\n",
    "                    # TRY: pulling only first part of street \n",
    "        \n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"sample-data/example4.osm\"\n",
    "\n",
    "# compile object for making comparisons against regex\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St.\": \"Street\",\n",
    "           \"Ave\": \"Avenue\",\n",
    "           \"Rd.\": \"Road\"\n",
    "          }\n",
    "\n",
    "\n",
    "# input: empty dict-like and string w/ name of street\n",
    "def audit_street_type(street_types, street_name):\n",
    "    # use regex compile object to find the last word in the street_name string\n",
    "    # traditionally the last word is the street, court, way, etc.\n",
    "    # return will either be a match object, or None\n",
    "    m = street_type_re.search(street_name)\n",
    "    \n",
    "    # if m is a match object (not None)\n",
    "    if m:\n",
    "        # .group() function pulls out the actual word\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "# quick test returns True or False depending on k value of an element\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    # open the osm file\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    \n",
    "    # initialize a dict-like using defaultdict and a set\n",
    "    street_types = defaultdict(set)\n",
    "    \n",
    "    # iteratively parse each element from OSM sequentially\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            # .iter creates new tree iterator from current element as root to iterate over (includes all sub elements)\n",
    "            # input param is optional and specifies the specific tags I want (here only looking for \"tags\")\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                # calling is_street_name, takes in a tag\n",
    "                # outputs True or False\n",
    "                if is_street_name(tag):\n",
    "                    # calling audit_street_type function\n",
    "                    # input params:\n",
    "                        # street_types dict-like (is empty at this point)\n",
    "                        # the v value from the tag (which is the name of the street)\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    # returns a dict-like\n",
    "    return street_types\n",
    "\n",
    "\n",
    "# input: incorrect name from st_types and the mapping dict\n",
    "def update_name(name, mapping):\n",
    "    \n",
    "    # match object for regex comparison \n",
    "    compare_name = street_type_re.search(name)\n",
    "    \n",
    "    # fetch the regex comparison\n",
    "    end_name = compare_name.group()\n",
    "    \n",
    "    # fetches the correct street naming based on mapping\n",
    "    new_street = mapping[end_name]\n",
    "    \n",
    "    # finds everything in front of the regex comparison\n",
    "    start_name = name.split(end_name,1)[0]\n",
    "    \n",
    "    name = start_name + new_street\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    # expecting a dict-like\n",
    "    st_types = audit(OSMFILE)\n",
    "    assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    # st_type is a single string (key)\n",
    "    # ways is a set with one or more values\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            # input: incorrect name from st_types and the mapping dict\n",
    "            better_name = update_name(name, mapping)\n",
    "            # prints incorrect name and what it will be mapped to\n",
    "            print (name, \"=>\", better_name)\n",
    "            # tests\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# REQS\n",
    "    # return a count of each of four tag types in a dict\n",
    "# EXEC\n",
    "    # key_type\n",
    "        # REQS\n",
    "            # input: element tag and keys dict\n",
    "            # output: an updated keys dict\n",
    "        # RULES\n",
    "            # k value of \"tag\" element must in one of the four categories\n",
    "        # COMP\n",
    "            # if not lower, then if not lower_colon, then if not problemchars, then other\n",
    "        # DECOMP\n",
    "            # EXPERIMENT: how to compare a string against a regex statement\n",
    "            # TRY: Set up regex comp and implement if/else\n",
    "                # EXPERIMENT: pull out the k value from <tag> elements\n",
    "                    # element.attrib['k']\n",
    "                # INVESTIGATE: why dict has wrong counts?\n",
    "                    # needed to use .seach instead of .match\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "\n",
    "    if element.tag == \"tag\":\n",
    "        # find the k value for each element\n",
    "        k_value = element.attrib['k']\n",
    "        \n",
    "        # check to see if k value is described by each regex\n",
    "        if lower.search(k_value):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(k_value):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(k_value):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        \n",
    "        # with each iteration of .iterparse(), key_type method is called\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    \n",
    "    # a dict \n",
    "    keys = process_map('sample-data/example2.osm')\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bunnies]",
   "language": "python",
   "name": "conda-env-bunnies-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
